{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "TLMt4Dz_rvKM",
        "CPsbhaSI4mX0",
        "bndvXBtjVJOL",
        "rrKguy7qYJCH",
        "KWQYN3tpIsrw",
        "Qr3zLEfxTLlW",
        "oIjJCywdINC-",
        "8eL6dJd_N9M4",
        "u5vqKJrLNC6V",
        "y7tcQBj7bM7C",
        "xfMx60mxiMtb",
        "3QWblPkwk52S",
        "RRP5tHrzj_jI",
        "E69mZP8forlS",
        "nubp-cdnsUAl",
        "GB4wA2-_snYc",
        "1mByPmXFuAnZ",
        "z41_Wvdcvm4u",
        "wV_MhEluxDSI",
        "GR2uWvrD1692",
        "hfuYuplh5NPl",
        "pshzblPhrPbG",
        "u4nwKdEWEQ_K",
        "kdu5YZMSFITU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd -"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3RVpjv3rekB",
        "outputId": "477bdac7-f2d1-431a-efb1-b663b7af1e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2fBHdThrsSa",
        "outputId": "661699a1-fd53-48f3-c779-080efd19b715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/ams_595_python_teaching"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGKmId6xWUrX",
        "outputId": "a9f3f3f6-245b-421d-ad55-2c3a42a7da71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ams_595_python_teaching\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 6 Neural Networks**"
      ],
      "metadata": {
        "id": "CMmwx2BAw7PZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recap: Logistic Regression"
      ],
      "metadata": {
        "id": "x9wRg5YAx6Jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we dive into neural networks, let's briefly recap what you've learned about logistic regression."
      ],
      "metadata": {
        "id": "8yEAANCIySAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. Logistic Regression Basics"
      ],
      "metadata": {
        "id": "oRa-QroWyUgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Binary Classification**: Logistic regression is a supervised learning algorithm used for binary classification problems, where the goal is to classify data into one of two classes (e.g., spam or not spam, fraud or not fraud).\n",
        "- S**igmoid Function**: Logistic regression uses the sigmoid function to map input features to a probability score between 0 and 1. The formula for logistic regression is: $ P(Y=1|X) = \\frac{1}{1 + e^{-(w_1X_1 + w_2X_2 + \\ldots + w_nX_n + b)}} $\n",
        "- **Cost Function**: The cost function in logistic regression is typically the log loss or cross-entropy loss, which measures the difference between predicted probabilities and actual labels.\n",
        "- **Gradient Descent**: To train a logistic regression model, we use gradient descent to minimize the cost function and find the optimal values of coefficients ($\\theta^*$) that make accurate predictions."
      ],
      "metadata": {
        "id": "UYrnUF2qyY4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. Limitations of Logistic Regression"
      ],
      "metadata": {
        "id": "QLF8cFZ3zJCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While logistic regression is a powerful algorithm, it has some limitations:\n",
        "\n",
        "* It is only suitable for binary classification, we need more powerful learning algorithms to achieve other tasks.\n",
        "* It can only model linear relationships between features and the target.\n",
        "* It may not perform well when dealing with complex, non-linear data."
      ],
      "metadata": {
        "id": "Mlq59Dfyzyuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Neural Networks"
      ],
      "metadata": {
        "id": "B8OEu3l40oqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's move on to the exciting world of neural networks, which can address some of the limitations of logistic regression.\n",
        "\n",
        "Data:\n",
        "\n",
        "![link text](https://sandipanweb.files.wordpress.com/2017/11/data1.png)\n",
        "\n",
        "Ref: https://sandipanweb.wordpress.com/2017/11/25/some-deep-learning-with-python-tensorflow-and-keras/\n",
        "\n",
        "This is actually linearly separable\n",
        "\n",
        "![link text](https://sandipanweb.files.wordpress.com/2017/11/kernel.png)\n",
        "\n",
        "To classify these data points, we can use linear classifiers such as logistic models, support vector machines, etc..\n",
        "\n",
        "However, in many, if not most, real life applications, we have data that looks like this:\n",
        "\n",
        "![link text](https://sandipanweb.files.wordpress.com/2017/11/flower.png)\n",
        "\n",
        "This is not linearly separable. Thus, we need more powerful models to achieve the same task.\n"
      ],
      "metadata": {
        "id": "RHqzyBN20uZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What Are Neural Networks?"
      ],
      "metadata": {
        "id": "pvpE2XB-0vKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural networks are a class of machine learning models inspired by the structure and function of the human brain. They consist of interconnected nodes (neurons) organized into layers. Neural networks are used for various tasks, including classification, regression, and even more complex tasks like image recognition and natural language processing."
      ],
      "metadata": {
        "id": "6--j_UVv02Gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Components of a Neural Network"
      ],
      "metadata": {
        "id": "Qivr_CBd1Lwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Input Layer: The input layer receives the features or data points. Each neuron in the input layer represents a feature.\n",
        "\n",
        "2. Hidden Layers: Between the input and output layers, there can be one or more hidden layers. These layers contain neurons that process the input data using weights and activation functions.\n",
        "\n",
        "3. Output Layer: The output layer provides the final prediction. The number of neurons in the output layer depends on the problem (e.g., one neuron for binary classification).\n",
        "\n",
        "4. Weights and Bias: Each connection between neurons is associated with a weight. These weights are adjusted during training to learn the underlying patterns in the data. A bias term is also used to shift the output of a neuron.\n",
        "\n",
        "5. Activation Functions: Activation functions introduce non-linearity into the model. Common activation functions include the sigmoid, ReLU (Rectified Linear Unit), and softmax functions."
      ],
      "metadata": {
        "id": "ZIZoM4-U1MeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "![link text](https://miro.medium.com/v2/resize:fit:1199/1*N8UXaiUKWurFLdmEhEHiWg.jpeg)\n",
        "Ref: https://miro.medium.com/v2/resize:fit:1199/1*N8UXaiUKWurFLdmEhEHiWg.jpeg\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_quhfPwS03zp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Deep Neural Networks work?"
      ],
      "metadata": {
        "id": "JnUlPQLy1reK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Many tasks can be viewed as functions. For example, image classification is a function that maps the input image to the class it belongs to.\n",
        "1. [**Universal Approximation Theorem**](https://en.wikipedia.org/wiki/Universal_approximation_theorem) for Functions, which suggests that neural networks can represent almost any function given a sufficient number of neurons in the hidden layers.\n",
        "2. **Universal Approximation Theorem for Operators** (Chen \\& Chen, IEEE Trans. Neural Netw., 1995)\n",
        "> Suppose that $\\sigma$ is a continuous non-polynomial function, $X$ is a Banach Space, $K_1 \\subset X, K_2 \\subset \\mathbb{R}^d$ are two compact sets in $X$ and $\\mathbb{R}^d$, respectively, $V$ is a compact set in $C\\left(K_1\\right), G$ is a nonlinear continuous operator, which maps $V$ into $C\\left(K_2\\right)$. Then for any $\\epsilon>0$, there are positive integers $n, p$, $m$, constants $c_i^k, \\xi_{i j}^k, \\theta_i^k, \\zeta_k \\in \\mathbb{R}, w_k \\in \\mathbb{R}^d, x_j \\in K_1, i=1, \\ldots, n$, $k=1, \\ldots, p, j=1, \\ldots, m$, such that\n",
        "$$\n",
        "|G(u)(y)-\\sum_{k=1}^p \\underbrace{\\sum_{i=1}^n c_i^k \\sigma\\left(\\sum_{j=1}^m \\xi_{i j}^k u\\left(x_j\\right)+\\theta_i^k\\right)}_{\\text {branch }} \\underbrace{\\sigma\\left(w_k \\cdot y+\\zeta_k\\right)}_{\\text {trunk }}|<\\epsilon\n",
        "$$\n",
        "holds for all $u \\in V$ and $y \\in K_2$."
      ],
      "metadata": {
        "id": "r9ZIiBy012CJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Process\n"
      ],
      "metadata": {
        "id": "n682ciRZ2wbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process of making predictions in a neural network is called the forward process. It involves the following steps:\n",
        "- Input Propagation: The input values are propagated through the network from the input layer to the output layer. Each neuron's output is computed based on its weighted sum of inputs and activation function.\n",
        "\n",
        "- Activation Function: The weighted sum is passed through the activation function to introduce non-linearity.\n",
        "\n",
        "- Output Prediction: The final output is produced by the output layer, which may represent probabilities for classification problems, the location of a certain object in a iamge, a sentence, etc.."
      ],
      "metadata": {
        "id": "VciaGAkp2z1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning in Neural Networks"
      ],
      "metadata": {
        "id": "TRAF-GR33NPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Forward Propagation: During forward propagation, the input data is fed into the network, and predictions are made.\n",
        "\n",
        "- Backpropagation: After making predictions, the network's performance is evaluated using a cost function, similar to logistic regression. Backpropagation is the process of calculating gradients of the cost function with respect to the weights and biases in the network. These gradients are used to update the weights and improve the model's performance."
      ],
      "metadata": {
        "id": "3Rq9aawo5D4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Illustration"
      ],
      "metadata": {
        "id": "ObsoSR7k8wPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional details and derivations were discussed during the class. If you missed the class, it is your responsibility to ensure that you understand how a basic feedforward neural network operates.\n",
        "\n",
        "Next week, we will start coding with Pytorch, a python machine learning framework."
      ],
      "metadata": {
        "id": "2JavRyjD8yiq"
      }
    }
  ]
}